{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3b030443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import ast\n",
    "\n",
    "from random import choices, choice\n",
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "457d0d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_code(name, directory='files'):\n",
    "    with open(f'{directory}/{name}', encoding='utf8') as f:\n",
    "        file = f.read()\n",
    "    return file\n",
    "    \n",
    "code = read_code('auto.py', 'files')\n",
    "plagiat1 = read_code('auto.py', 'plagiat1')\n",
    "plagiat2 = read_code('auto.py', 'plagiat2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f9b6076",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "\n",
      "import pathlib\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "from etna.auto import Auto\n",
      "from etna.datasets import TSDataset\n",
      "from etna.metrics import SMAPE\n",
      "\n",
      "CURRENT_DIR_PATH = pathlib.Path(__file__).parent\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    df = pd.read_csv(CURRENT_DIR_PATH / \"data\" / \"example_dataset.csv\")\n",
      "\n",
      "    ts = TSDataset.to_dataset(df)\n",
      "    ts = TSDataset(ts, freq=\"D\")\n",
      "\n",
      "    # Create Auto object for greedy search\n",
      "    # All trials will be saved in sqlite database\n",
      "    # You can use it later for analysis with ``Auto.summary``\n",
      "    auto = Auto(\n",
      "        target_metric=SMAPE(),\n",
      "        horizon=14,\n",
      "        experiment_folder=\"auto-example\",\n",
      "    )\n",
      "\n",
      "    # Get best pipeline\n",
      "    best_pipeline = auto.fit(ts, catch=(Exception,))\n",
      "    print(best_pipeline)\n",
      "\n",
      "    # Get all metrics of greedy search\n",
      "    print(auto.summary())\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "import pathlib\n",
      "import pandas as pd\n",
      "from etna.auto import Auto\n",
      "from etna.datasets import TSDataset\n",
      "from etna.metrics import SMAPE\n",
      "CURRENT_DIR_PATH = pathlib.Path(__file__).parent\n",
      "if __name__ == '__main__':\n",
      "    df = pd.read_csv(CURRENT_DIR_PATH / 'data' / 'example_dataset.csv')\n",
      "    ts = TSDataset.to_dataset(df)\n",
      "    ts = TSDataset(ts, freq='D')\n",
      "    auto = Auto(target_metric=SMAPE(), horizon=14, experiment_folder='auto-example')\n",
      "    best_pipeline = auto.fit(ts, catch=(EXCEPTION,))\n",
      "    print(best_pipeline)\n",
      "    print(auto.summary())\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "import pathlib\n",
      "import pandas as pd\n",
      "from etna.auto import Auto\n",
      "from etna.datasets import TSDataset\n",
      "from etna.metrics import SMAPE\n",
      "CURRENT_DIR_P_ATH = pathlib.Path(__file__).parent\n",
      "if __name__ == '__main__':\n",
      "    df = pd.read_csv(CURRENT_DIR_P_ATH / 'data' / 'example_dataset.csv')\n",
      "    t = TSDataset.to_dataset(df)\n",
      "    t = TSDataset(t, freq='D')\n",
      "    auto = Auto(target_metric=SMAPE(), horizon=14, experiment_folder='auto-example')\n",
      "    best_pipeline = auto.fit(t, catch=(Exception,))\n",
      "    print(best_pipeline)\n",
      "    print(auto.summary())\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Пример оригинального и сплагиаченного кода\n",
    "\n",
    "for program in code, plagiat1, plagiat2:\n",
    "    print(50*'-' + '\\n\\n' + program)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5666d37e",
   "metadata": {},
   "source": [
    "Мы хотим создать некоторый алфавит типов, из которых будут состоять наши слова-программы\n",
    "Для успешного обучения, мы ограничим число используемых типов каким-то разумным значением\n",
    "Найдём наиболее часто встречающиеся типы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "db76e2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeVisitor(ast.NodeVisitor):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.code_list = []\n",
    "    \n",
    "    def generic_visit(self, node):\n",
    "        self.code_list.append(type(node))\n",
    "        super().generic_visit(node)\n",
    "        \n",
    "def code_to_list(code):\n",
    "    c = CodeVisitor()\n",
    "    tree = ast.parse(code)\n",
    "    c.visit(tree)\n",
    "    return c.code_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "42129c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<class '_ast.Load'>, 66931)\n",
      "(<class '_ast.Name'>, 49024)\n",
      "(<class '_ast.Constant'>, 23135)\n",
      "(<class '_ast.Attribute'>, 18483)\n",
      "(<class '_ast.Call'>, 14924)\n",
      "(<class '_ast.Store'>, 11112)\n",
      "(<class '_ast.Assign'>, 8483)\n",
      "(<class '_ast.keyword'>, 7058)\n",
      "(<class '_ast.arg'>, 5518)\n",
      "(<class '_ast.Subscript'>, 5080)\n",
      "(<class '_ast.Index'>, 4855)\n",
      "(<class '_ast.Expr'>, 3534)\n",
      "(<class '_ast.List'>, 2772)\n",
      "(<class '_ast.Tuple'>, 2625)\n",
      "(<class '_ast.alias'>, 2571)\n",
      "(<class '_ast.arguments'>, 2544)\n",
      "(<class '_ast.FunctionDef'>, 2409)\n",
      "(<class '_ast.BinOp'>, 2117)\n",
      "(<class '_ast.Compare'>, 1747)\n",
      "(<class '_ast.ImportFrom'>, 1668)\n",
      "(<class '_ast.Return'>, 1224)\n",
      "(<class '_ast.If'>, 1133)\n",
      "(<class '_ast.Eq'>, 892)\n",
      "(<class '_ast.Assert'>, 857)\n",
      "(<class '_ast.Slice'>, 830)\n",
      "(<class '_ast.Add'>, 823)\n",
      "(<class '_ast.UnaryOp'>, 809)\n",
      "(<class '_ast.Import'>, 687)\n",
      "(<class '_ast.Dict'>, 685)\n",
      "(<class '_ast.USub'>, 639)\n",
      "(<class '_ast.For'>, 528)\n",
      "(<class '_ast.Mult'>, 477)\n",
      "(<class '_ast.Sub'>, 451)\n",
      "(<class '_ast.ExtSlice'>, 445)\n",
      "(<class '_ast.Div'>, 362)\n",
      "(<class '_ast.comprehension'>, 319)\n",
      "(<class '_ast.Raise'>, 317)\n",
      "(<class '_ast.ClassDef'>, 311)\n",
      "(<class '_ast.With'>, 302)\n",
      "(<class '_ast.withitem'>, 302)\n",
      "(<class '_ast.FormattedValue'>, 296)\n",
      "(<class '_ast.Module'>, 278)\n",
      "(<class '_ast.JoinedStr'>, 242)\n",
      "(<class '_ast.ListComp'>, 238)\n",
      "(<class '_ast.AnnAssign'>, 236)\n",
      "(<class '_ast.Is'>, 181)\n",
      "(<class '_ast.Not'>, 153)\n",
      "(<class '_ast.IsNot'>, 148)\n",
      "(<class '_ast.BoolOp'>, 142)\n",
      "(<class '_ast.Lambda'>, 135)\n",
      "(<class '_ast.AugAssign'>, 120)\n",
      "(<class '_ast.IfExp'>, 114)\n",
      "(<class '_ast.NotEq'>, 111)\n",
      "(<class '_ast.In'>, 110)\n",
      "(<class '_ast.Gt'>, 99)\n",
      "(<class '_ast.Lt'>, 97)\n",
      "(<class '_ast.And'>, 90)\n",
      "(<class '_ast.Starred'>, 64)\n",
      "(<class '_ast.Set'>, 62)\n",
      "(<class '_ast.GtE'>, 53)\n",
      "(<class '_ast.Or'>, 52)\n",
      "(<class '_ast.Pow'>, 47)\n",
      "(<class '_ast.NotIn'>, 36)\n",
      "(<class '_ast.DictComp'>, 34)\n",
      "(<class '_ast.FloorDiv'>, 32)\n",
      "(<class '_ast.GeneratorExp'>, 27)\n",
      "(<class '_ast.Mod'>, 25)\n",
      "(<class '_ast.Continue'>, 24)\n",
      "(<class '_ast.ExceptHandler'>, 24)\n",
      "(<class '_ast.Pass'>, 23)\n",
      "(<class '_ast.Try'>, 23)\n",
      "(<class '_ast.LtE'>, 23)\n",
      "(<class '_ast.While'>, 18)\n",
      "(<class '_ast.Invert'>, 17)\n",
      "(<class '_ast.SetComp'>, 14)\n",
      "(<class '_ast.Yield'>, 11)\n",
      "(<class '_ast.BitAnd'>, 11)\n",
      "(<class '_ast.Break'>, 10)\n",
      "(<class '_ast.BitOr'>, 6)\n",
      "(<class '_ast.Delete'>, 5)\n",
      "(<class '_ast.Del'>, 5)\n",
      "(<class '_ast.MatMult'>, 2)\n",
      "(<class '_ast.LShift'>, 1)\n"
     ]
    }
   ],
   "source": [
    "types = {}\n",
    "for name in os.listdir('files'):\n",
    "    \n",
    "    with open(f'files/{name}', encoding='utf8') as file:\n",
    "        for line in code_to_list(file.read()):\n",
    "            if line in types:\n",
    "                types[line] += 1\n",
    "            else:\n",
    "                types[line] = 1\n",
    "            \n",
    "\n",
    "print(*sorted(types.items(), key=lambda x: x[1], reverse=True), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fffc3fc",
   "metadata": {},
   "source": [
    "ClassDef является важнейшим элементом синтаксиса, который, тем не менее, встречается крайне редко. Давайте выбросим из словаря все синтаксические конструкции, встречающиеся реже, чем ClassDef."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb088b43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_ast.Import,\n",
       " _ast.alias,\n",
       " _ast.ImportFrom,\n",
       " _ast.ClassDef,\n",
       " _ast.Name,\n",
       " _ast.Load,\n",
       " _ast.Expr,\n",
       " _ast.Constant,\n",
       " _ast.FunctionDef,\n",
       " _ast.arguments,\n",
       " _ast.arg,\n",
       " _ast.Subscript,\n",
       " _ast.Index,\n",
       " _ast.Assign,\n",
       " _ast.Attribute,\n",
       " _ast.Store,\n",
       " _ast.If,\n",
       " _ast.Call,\n",
       " _ast.Return,\n",
       " _ast.ExtSlice,\n",
       " _ast.Slice,\n",
       " _ast.BinOp,\n",
       " _ast.Add,\n",
       " _ast.keyword,\n",
       " _ast.List,\n",
       " _ast.Tuple,\n",
       " _ast.Sub,\n",
       " _ast.Compare,\n",
       " _ast.Eq,\n",
       " _ast.For,\n",
       " _ast.Mult,\n",
       " _ast.Div,\n",
       " _ast.Raise,\n",
       " _ast.UnaryOp,\n",
       " _ast.USub,\n",
       " _ast.Dict,\n",
       " _ast.comprehension,\n",
       " _ast.Assert]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet = [name for name, value in filter(lambda x: x[1] > 310, types.items())]\n",
    "with open('aplhabet.txt', 'w') as alpha:\n",
    "    for line in alphabet:\n",
    "        alpha.write(str(line) + '\\n')\n",
    "alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "fd6e3bdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"<class '_ast.Import'>\", \n",
      "\"<class '_ast.alias'>\", \n",
      "\"<class '_ast.ImportFrom'>\", \n",
      "\"<class '_ast.ClassDef'>\", \n",
      "\"<class '_ast.Name'>\", \n",
      "\"<class '_ast.Load'>\", \n",
      "\"<class '_ast.Expr'>\", \n",
      "\"<class '_ast.Constant'>\", \n",
      "\"<class '_ast.FunctionDef'>\", \n",
      "\"<class '_ast.arguments'>\", \n",
      "\"<class '_ast.arg'>\", \n",
      "\"<class '_ast.Subscript'>\", \n",
      "\"<class '_ast.Index'>\", \n",
      "\"<class '_ast.Assign'>\", \n",
      "\"<class '_ast.Attribute'>\", \n",
      "\"<class '_ast.Store'>\", \n",
      "\"<class '_ast.If'>\", \n",
      "\"<class '_ast.Call'>\", \n",
      "\"<class '_ast.Return'>\", \n",
      "\"<class '_ast.ExtSlice'>\", \n",
      "\"<class '_ast.Slice'>\", \n",
      "\"<class '_ast.BinOp'>\", \n",
      "\"<class '_ast.Add'>\", \n",
      "\"<class '_ast.keyword'>\", \n",
      "\"<class '_ast.List'>\", \n",
      "\"<class '_ast.Tuple'>\", \n",
      "\"<class '_ast.Sub'>\", \n",
      "\"<class '_ast.Compare'>\", \n",
      "\"<class '_ast.Eq'>\", \n",
      "\"<class '_ast.For'>\", \n",
      "\"<class '_ast.Mult'>\", \n",
      "\"<class '_ast.Div'>\", \n",
      "\"<class '_ast.Raise'>\", \n",
      "\"<class '_ast.UnaryOp'>\", \n",
      "\"<class '_ast.USub'>\", \n",
      "\"<class '_ast.Dict'>\", \n",
      "\"<class '_ast.comprehension'>\", \n",
      "\"<class '_ast.Assert'>\", \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print('\"' + str(a) + '\", ') for a in alphabet]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281d4659",
   "metadata": {},
   "source": [
    "Теперь можно каждую программу записать как последовательность символов: каждой операции будет соответствовать какая-то \"буква\" алфавита. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69aaac7",
   "metadata": {},
   "source": [
    "Также отметим, что некоторые файлы невозможно запарсить с помощью библиотеки ast, если такие файлы содержат синтаксическую ошибку. Таких файлов всего 12 и 16  из 306 в первой и второй папке соответственно. Для практического применения знание о наличии плагиата в неработающей программе практически лишёно смысла поскольку ключевым фактором оценки такой программы будет банальная невозможность её запустить. По этой причине я буду считать эти файлы outlier-ами и не буду учитывать их при обучении модели.\n",
    "\n",
    "На этапе предсказаний я дам такой программе нулевую степень сходства с любой другой программой (можно было бы давать полное сходство с другой программой, если та тоже содержит синтаксическую ошибку, но такую реализацию было бы тяжелее реализовать на практике)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6ac1dd",
   "metadata": {},
   "source": [
    "Перепишем code_to_list учитывая новый алфавит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7156ceb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{_ast.Import: 0,\n",
       " _ast.alias: 1,\n",
       " _ast.ImportFrom: 2,\n",
       " _ast.ClassDef: 3,\n",
       " _ast.Name: 4,\n",
       " _ast.Load: 5,\n",
       " _ast.Expr: 6,\n",
       " _ast.Constant: 7,\n",
       " _ast.FunctionDef: 8,\n",
       " _ast.arguments: 9,\n",
       " _ast.arg: 10,\n",
       " _ast.Subscript: 11,\n",
       " _ast.Index: 12,\n",
       " _ast.Assign: 13,\n",
       " _ast.Attribute: 14,\n",
       " _ast.Store: 15,\n",
       " _ast.If: 16,\n",
       " _ast.Call: 17,\n",
       " _ast.Return: 18,\n",
       " _ast.ExtSlice: 19,\n",
       " _ast.Slice: 20,\n",
       " _ast.BinOp: 21,\n",
       " _ast.Add: 22,\n",
       " _ast.keyword: 23,\n",
       " _ast.List: 24,\n",
       " _ast.Tuple: 25,\n",
       " _ast.Sub: 26,\n",
       " _ast.Compare: 27,\n",
       " _ast.Eq: 28,\n",
       " _ast.For: 29,\n",
       " _ast.Mult: 30,\n",
       " _ast.Div: 31,\n",
       " _ast.Raise: 32,\n",
       " _ast.UnaryOp: 33,\n",
       " _ast.USub: 34,\n",
       " _ast.Dict: 35,\n",
       " _ast.comprehension: 36,\n",
       " _ast.Assert: 37}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet_mapping = {word: index for index, word in enumerate(alphabet)}\n",
    "alphabet_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b84437ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_to_list(code):\n",
    "    c = CodeVisitor()\n",
    "    tree = ast.parse(code)\n",
    "    c.visit(tree)\n",
    "    return list(map(lambda x: alphabet_mapping[x], filter(lambda x: x in alphabet, c.code_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81545554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "cnt_errors = 0\n",
    "cnt_match = 0\n",
    "for name in os.listdir('files'):\n",
    "    code1 = read_code(name, 'files')\n",
    "    code2 = read_code(name, 'plagiat1')\n",
    "    try:\n",
    "        if code_to_list(code1) == code_to_list(code2):\n",
    "            cnt_match += 1\n",
    "    except SyntaxError:\n",
    "        cnt_errors += 1\n",
    "        \n",
    "print(cnt_errors)\n",
    "print(cnt_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1675228",
   "metadata": {},
   "source": [
    "Давайте удалим те файлы, которые невозможно запарсить. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "f49e7700",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_workarounds.py',\n",
       " 'base.py',\n",
       " 'bn_inception_simple.py',\n",
       " 'cars196.py',\n",
       " 'classification.py',\n",
       " 'date_flags.py',\n",
       " 'deepar.py',\n",
       " 'eda_utils.py',\n",
       " 'eval-speed.py',\n",
       " 'generator.py',\n",
       " 'imputation.py',\n",
       " 'iql.py',\n",
       " 'load-metrics.py',\n",
       " 'mixins.py',\n",
       " 'optuna_example.py',\n",
       " 'plotters.py',\n",
       " 'rnn.py',\n",
       " 'runner.py',\n",
       " 'sac_n.py',\n",
       " 'sampler.py',\n",
       " 'statistics.py',\n",
       " 'test_add_constant_transform.py',\n",
       " 'test_autoarima_model.py',\n",
       " 'test_dirac.py',\n",
       " 'test_predictability.py',\n",
       " 'test_timeflags_transform.py',\n",
       " 'test_voting_ensemble.py',\n",
       " 'trend.py'}"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_files = set()\n",
    "\n",
    "\n",
    "for name in os.listdir('files'):\n",
    "    code1 = read_code(name, 'plagiat2')\n",
    "    code2 = read_code(name, 'plagiat1')\n",
    "    try:\n",
    "        code_to_list(code1)\n",
    "        code_to_list(code2)\n",
    "    except SyntaxError:\n",
    "        error_files.add(name)\n",
    "        \n",
    "error_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "9a4e3ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in error_files:\n",
    "    for directory in 'files', 'plagiat1', 'plagiat2':\n",
    "        os.remove(f'{directory}/{name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce89941a",
   "metadata": {},
   "source": [
    "Осталось написать алгоритм для нахождения расстояния Левенштейна. При этом у нас остаётся выбор параметров модели: мы можем установить цену удаления/вставки той или иной буквы, а также цену замены буквы i на букву j. В алфавите из 39 параметров это даст 39 * 2 + 39 * 38 = 1560 параметров. Очевидно, это будет слишком много для того чтобы хорошо обучить модель всего на 278 файлах (мы можем составить 278 * 277 пар файлов, чего было бы достаточно и для обучения и для проверки модели, однако, вероятнее всего, на практике при использовании модели, примерно равная вероятность копирайта и не-копирайта)\n",
    "\n",
    "Скорее всего введение даже 39 или 78 параметров будет излишним. Поэтому у моей модели будет всего 3 параметра: цена удаления, цена вставки и цена замены букв. При таком количестве параметров мы сможем вместо градиентного спуска применить grid search и найти оптимальные параметры непосредственно перебором.\n",
    "\n",
    "## Осталось написать модель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e9b449",
   "metadata": {},
   "source": [
    "Начнём с алгоритма:\n",
    "Обычный алгоритм левенштейна имеет большой недостаток, который заключается в том, что длинные последовательности, даже если они похожи, будут выдавать большие значения. Поэтому мы нормализуем значение, разделив его на наибольшее из длин последовательностей символов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "55794d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wagner_fisher(code1: list, code2: list, rep_cost=1, del_cost=1, ins_cost=1):\n",
    "    prev_line = [j * ins_cost for j in range(len(code2))]\n",
    "    new_line = [0] * len(code2)\n",
    "    for i in range(len(code1)):\n",
    "        for j in range(len(code2)):\n",
    "            if j == 0:\n",
    "                new_line[0] = i * del_cost\n",
    "            else:\n",
    "                new_line[j] = min(prev_line[j] + del_cost, \n",
    "                                  new_line[j - 1] + ins_cost,\n",
    "                                  prev_line[j - 1] + rep_cost * (code1[i] != code2[j]))\n",
    "        prev_line, new_line = new_line, [0] * len(code2)\n",
    "    try:\n",
    "        return 1 - prev_line[-1] / (rep_cost * max(len(code2), len(code1)))\n",
    "    except IndexError:\n",
    "        if len(code1) == len(code2):\n",
    "            return 1\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3083ac",
   "metadata": {},
   "source": [
    "Давайте посмотрим на числа, которые выдаёт наш алгоритм при поиске плагиата."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b7d14d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['add_constant.py',\n",
       " 'any_percent_bc.py',\n",
       " 'apply_lambda.py',\n",
       " 'arima.py',\n",
       " 'assembling_pipelines.py',\n",
       " 'auto.py',\n",
       " 'autoarima.py',\n",
       " 'autoregressive_pipeline.py',\n",
       " 'awac.py',\n",
       " 'backtest_command.py',\n",
       " 'base_change_points.py',\n",
       " 'basic.py',\n",
       " 'binseg.py',\n",
       " 'callbacks.py',\n",
       " 'catboost.py',\n",
       " 'categorical.py',\n",
       " 'cgd.py',\n",
       " 'change_points_segmentation.py',\n",
       " 'change_points_trend.py',\n",
       " 'check_imported_dependencies.py',\n",
       " 'cifar.py',\n",
       " 'classifier.py',\n",
       " 'cnn.py',\n",
       " 'collection.py',\n",
       " 'common.py',\n",
       " 'conf.py',\n",
       " 'config.py',\n",
       " 'config_sampler.py',\n",
       " 'conftest.py',\n",
       " 'console_logger.py',\n",
       " 'cql.py',\n",
       " 'criterion.py',\n",
       " 'cub200.py',\n",
       " 'cutout.py',\n",
       " 'cval.py',\n",
       " 'datasets_generation.py',\n",
       " 'deadline_ma.py',\n",
       " 'debug.py',\n",
       " 'decorators.py',\n",
       " 'defaults.py',\n",
       " 'density_outliers.py',\n",
       " 'detrend.py',\n",
       " 'differencing.py',\n",
       " 'dirac.py',\n",
       " 'direct_ensemble.py',\n",
       " 'distance_matrix.py',\n",
       " 'distribution.py',\n",
       " 'dt.py',\n",
       " 'dtw_clustering.py',\n",
       " 'dtw_distance.py',\n",
       " 'dummy.py',\n",
       " 'edac.py',\n",
       " 'embedder.py',\n",
       " 'euclidean_clustering.py',\n",
       " 'euclidean_distance.py',\n",
       " 'evaluate.py',\n",
       " 'feature_importance.py',\n",
       " 'file_logger.py',\n",
       " 'filter.py',\n",
       " 'flower102.py',\n",
       " 'forecast_command.py',\n",
       " 'forward.py',\n",
       " 'fourier.py',\n",
       " 'functional_metrics.py',\n",
       " 'gale_shapley.py',\n",
       " 'generate-reality.py',\n",
       " 'gradient.py',\n",
       " 'hist_outliers.py',\n",
       " 'holiday.py',\n",
       " 'holt_winters.py',\n",
       " 'hopt.py',\n",
       " 'image.py',\n",
       " 'imagenet.py',\n",
       " 'imagenetlt.py',\n",
       " 'imagenette.py',\n",
       " 'initializer.py',\n",
       " 'inshop.py',\n",
       " 'intervals_metrics.py',\n",
       " 'io.py',\n",
       " 'knn.py',\n",
       " 'lags.py',\n",
       " 'lfw.py',\n",
       " 'linear.py',\n",
       " 'load-best-seeds-metrics.py',\n",
       " 'local.py',\n",
       " 'log.py',\n",
       " 'lossy.py',\n",
       " 'main.py',\n",
       " 'mean_segment_encoder.py',\n",
       " 'median_outliers.py',\n",
       " 'merged.py',\n",
       " 'metrics.py',\n",
       " 'mlp.py',\n",
       " 'mnist.py',\n",
       " 'model.py',\n",
       " 'moving_average.py',\n",
       " 'mrmr_selection.py',\n",
       " 'multisim.py',\n",
       " 'mxnet.py',\n",
       " 'naive.py',\n",
       " 'nearest.py',\n",
       " 'normal.py',\n",
       " 'notebook_codespell.py',\n",
       " 'notebook_runner.py',\n",
       " 'optimizer.py',\n",
       " 'pairs.py',\n",
       " 'parametrization.py',\n",
       " 'pipeline.py',\n",
       " 'point_outliers.py',\n",
       " 'pooling.py',\n",
       " 'power.py',\n",
       " 'predictability.py',\n",
       " 'prediction_interval_outliers.py',\n",
       " 'preload.py',\n",
       " 'print-stages.py',\n",
       " 'prophet.py',\n",
       " 'proxynca.py',\n",
       " 'pytorch_forecasting.py',\n",
       " 'py_spy_to_df.py',\n",
       " 'readme_updater.py',\n",
       " 'regularization_search.py',\n",
       " 'release.py',\n",
       " 'relevance.py',\n",
       " 'relevance_table.py',\n",
       " 'remove_old_images.py',\n",
       " 'resample.py',\n",
       " 'resolvers.py',\n",
       " 'rotation.py',\n",
       " 'run.py',\n",
       " 'sarimax.py',\n",
       " 'scale-images.py',\n",
       " 'scalers.py',\n",
       " 'scheduler.py',\n",
       " 'scorer.py',\n",
       " 'search.py',\n",
       " 'seasonal_ma.py',\n",
       " 'segment_encoder.py',\n",
       " 'serialize.py',\n",
       " 'settings.py',\n",
       " 'setup.py',\n",
       " 'shell.py',\n",
       " 'significance_tests.py',\n",
       " 'sklearn.py',\n",
       " 'sop.py',\n",
       " 'special_days.py',\n",
       " 'split.py',\n",
       " 'stacking_ensemble.py',\n",
       " 'stanforddogs.py',\n",
       " 'stl.py',\n",
       " 'svhn.py',\n",
       " 'sweeps_example.py',\n",
       " 'tbats.py',\n",
       " 'td3_bc.py',\n",
       " 'templates.py',\n",
       " 'test_assembling_pipelines.py',\n",
       " 'test_auto.py',\n",
       " 'test_autoregressive_pipeline.py',\n",
       " 'test_backtest.py',\n",
       " 'test_base.py',\n",
       " 'test_base_change_points.py',\n",
       " 'test_base_feature_selection_transform.py',\n",
       " 'test_binseg_trend_transform.py',\n",
       " 'test_catboost.py',\n",
       " 'test_categorical_transform.py',\n",
       " 'test_change_points_segmentation_transform.py',\n",
       " 'test_change_points_trend_transform.py',\n",
       " 'test_classification.py',\n",
       " 'test_classifier.py',\n",
       " 'test_clustering.py',\n",
       " 'test_commands.py',\n",
       " 'test_common.py',\n",
       " 'test_confidence_interval_outliers.py',\n",
       " 'test_config.py',\n",
       " 'test_config_sampler.py',\n",
       " 'test_console_logger.py',\n",
       " 'test_criterion.py',\n",
       " 'test_dataset.py',\n",
       " 'test_datasets_generation.py',\n",
       " 'test_dateflags_transform.py',\n",
       " 'test_deepar.py',\n",
       " 'test_density_outliers.py',\n",
       " 'test_detrend_transform.py',\n",
       " 'test_differencing_transform.py',\n",
       " 'test_direct_ensemble.py',\n",
       " 'test_distances.py',\n",
       " 'test_distance_matrix.py',\n",
       " 'test_eda_utils.py',\n",
       " 'test_ensemble_mixin.py',\n",
       " 'test_feature_importance_transform.py',\n",
       " 'test_file_logger.py',\n",
       " 'test_filter_transform.py',\n",
       " 'test_find_change_points.py',\n",
       " 'test_forecast.py',\n",
       " 'test_fourier_transform.py',\n",
       " 'test_functional_metrics.py',\n",
       " 'test_gale_shapley_transform.py',\n",
       " 'test_hist_outliers.py',\n",
       " 'test_holiday_transform.py',\n",
       " 'test_holt_winters_model.py',\n",
       " 'test_impute_transform.py',\n",
       " 'test_interface.py',\n",
       " 'test_intervals_metrics.py',\n",
       " 'test_lag_transform.py',\n",
       " 'test_lambda_transform.py',\n",
       " 'test_linear_model.py',\n",
       " 'test_local.py',\n",
       " 'test_log_transform.py',\n",
       " 'test_mean_segment_encoder_transform.py',\n",
       " 'test_median_outliers.py',\n",
       " 'test_metrics.py',\n",
       " 'test_metrics_utils.py',\n",
       " 'test_mixins.py',\n",
       " 'test_mlp.py',\n",
       " 'test_model.py',\n",
       " 'test_mrmr.py',\n",
       " 'test_multisim.py',\n",
       " 'test_nearest.py',\n",
       " 'test_normal.py',\n",
       " 'test_optimizer.py',\n",
       " 'test_outliers_transform.py',\n",
       " 'test_parametrization.py',\n",
       " 'test_pipeline.py',\n",
       " 'test_plotters.py',\n",
       " 'test_pool.py',\n",
       " 'test_power_transform.py',\n",
       " 'test_predict.py',\n",
       " 'test_prophet.py',\n",
       " 'test_proxynca.py',\n",
       " 'test_pytorch_forecasting_transform.py',\n",
       " 'test_quality.py',\n",
       " 'test_regularization_search.py',\n",
       " 'test_relevance.py',\n",
       " 'test_relevance_table.py',\n",
       " 'test_reproducibility.py',\n",
       " 'test_resample_transform.py',\n",
       " 'test_rnn.py',\n",
       " 'test_sampler.py',\n",
       " 'test_sarimax_model.py',\n",
       " 'test_scalers_transform.py',\n",
       " 'test_segment_encoder_transform.py',\n",
       " 'test_simple_models.py',\n",
       " 'test_sklearn.py',\n",
       " 'test_sklearn_transform_interface.py',\n",
       " 'test_special_days_transform.py',\n",
       " 'test_stacking_ensemble.py',\n",
       " 'test_stages.py',\n",
       " 'test_statistics_transform.py',\n",
       " 'test_stl_transform.py',\n",
       " 'test_tbats.py',\n",
       " 'test_tft.py',\n",
       " 'test_to_dict.py',\n",
       " 'test_transform.py',\n",
       " 'test_transform_quantiles.py',\n",
       " 'test_trend_transform.py',\n",
       " 'test_tsfresh.py',\n",
       " 'test_utils.py',\n",
       " 'test_verification.py',\n",
       " 'test_vmf.py',\n",
       " 'test_wandb_logger.py',\n",
       " 'test_weasel.py',\n",
       " 'test_wrapper.py',\n",
       " 'tft.py',\n",
       " 'time_flags.py',\n",
       " 'torch.py',\n",
       " 'trace.py',\n",
       " 'trainer.py',\n",
       " 'tsdataset.py',\n",
       " 'tsfresh.py',\n",
       " 'utils.py',\n",
       " 'variance_scheduler.py',\n",
       " 'verification.py',\n",
       " 'vmf.py',\n",
       " 'voting_ensemble.py',\n",
       " 'wandb_logger.py',\n",
       " 'weasel.py',\n",
       " 'wrapper.py',\n",
       " '__init__.py',\n",
       " '__main__.py']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4a5fd2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add_constant.py \n",
      " 0.5408805031446541\n",
      "any_percent_bc.py \n",
      " 0.8448406676783005\n",
      "apply_lambda.py \n",
      " 0.605072463768116\n",
      "arima.py \n",
      " 0.9969418960244648\n",
      "assembling_pipelines.py \n",
      " 1.0\n",
      "auto.py \n",
      " 1.0\n",
      "autoarima.py \n",
      " 0.7517241379310344\n",
      "autoregressive_pipeline.py \n",
      " 0.6637931034482758\n",
      "awac.py \n",
      " 0.5698308001147118\n",
      "backtest_command.py \n",
      " 1.0\n",
      "base_change_points.py \n",
      " 0.8184143222506394\n",
      "basic.py \n",
      " 1.0\n",
      "binseg.py \n",
      " 1.0\n",
      "callbacks.py \n",
      " 1.0\n",
      "catboost.py \n",
      " 0.8667334669338678\n",
      "categorical.py \n",
      " 0.7149187592319055\n",
      "cgd.py \n",
      " 0.9936507936507937\n",
      "change_points_segmentation.py \n",
      " 0.6207865168539326\n",
      "change_points_trend.py \n",
      " 0.6933667083854819\n",
      "check_imported_dependencies.py \n",
      " 1.0\n",
      "cifar.py \n",
      " 0.5985915492957746\n",
      "classifier.py \n",
      " 0.6595092024539877\n",
      "cnn.py \n",
      " 0.6098066298342542\n",
      "collection.py \n",
      " 0.6556145004420866\n",
      "common.py \n",
      " 0.971671388101983\n",
      "conf.py \n",
      " 0.9927797833935018\n",
      "config.py \n",
      " 0.9912663755458515\n",
      "config_sampler.py \n",
      " 0.6134751773049645\n",
      "conftest.py \n",
      " 1.0\n",
      "console_logger.py \n",
      " 0.44318181818181823\n",
      "cql.py \n",
      " 0.7162837162837163\n",
      "criterion.py \n",
      " 0.40685543964232485\n",
      "cub200.py \n",
      " 0.6904276985743381\n",
      "cutout.py \n",
      " 0.9864864864864865\n",
      "cval.py \n",
      " 0.9918588873812755\n",
      "datasets_generation.py \n",
      " 0.9931623931623932\n",
      "deadline_ma.py \n",
      " 0.6717352415026834\n",
      "debug.py \n",
      " 0.4933333333333333\n",
      "decorators.py \n",
      " 1.0\n",
      "defaults.py \n",
      " 1.0\n",
      "density_outliers.py \n",
      " 0.996116504854369\n",
      "detrend.py \n",
      " 0.615748031496063\n",
      "differencing.py \n",
      " 0.642512077294686\n",
      "dirac.py \n",
      " 0.5274261603375527\n",
      "direct_ensemble.py \n",
      " 0.5559502664298401\n",
      "distance_matrix.py \n",
      " 0.5141430948419301\n",
      "distribution.py \n",
      " 0.9393939393939394\n",
      "dt.py \n",
      " 0.8658738938053098\n",
      "dtw_clustering.py \n",
      " 0.9272727272727272\n",
      "dtw_distance.py \n",
      " 0.4643527204502814\n",
      "dummy.py \n",
      " 0.4473684210526315\n",
      "edac.py \n",
      " 0.7054889298892989\n",
      "embedder.py \n",
      " 0.6844563042028018\n",
      "euclidean_clustering.py \n",
      " 0.9636363636363636\n",
      "euclidean_distance.py \n",
      " 0.8520710059171598\n",
      "evaluate.py \n",
      " 0.9887640449438202\n",
      "feature_importance.py \n",
      " 0.547945205479452\n",
      "file_logger.py \n",
      " 0.6380543633762518\n",
      "filter.py \n",
      " 0.846938775510204\n",
      "flower102.py \n",
      " 0.8242677824267782\n",
      "forecast_command.py \n",
      " 1.0\n",
      "forward.py \n",
      " 0.998193315266486\n",
      "fourier.py \n",
      " 0.6750972762645915\n",
      "functional_metrics.py \n",
      " 0.9867986798679867\n",
      "gale_shapley.py \n",
      " 0.5688859591298616\n",
      "generate-reality.py \n",
      " 0.9863813229571985\n",
      "gradient.py \n",
      " 0.46875\n",
      "hist_outliers.py \n",
      " 0.9979757085020243\n",
      "holiday.py \n",
      " 0.8840579710144928\n",
      "holt_winters.py \n",
      " 0.7809215844785772\n",
      "hopt.py \n",
      " 0.9692307692307692\n",
      "image.py \n",
      " 0.9053452115812918\n",
      "imagenet.py \n",
      " 0.9340974212034384\n",
      "imagenetlt.py \n",
      " 0.6835443037974683\n",
      "imagenette.py \n",
      " 0.9245283018867925\n",
      "initializer.py \n",
      " 0.5254237288135593\n",
      "inshop.py \n",
      " 0.9881656804733728\n",
      "intervals_metrics.py \n",
      " 0.9520865533230294\n",
      "io.py \n",
      " 0.9850746268656716\n",
      "knn.py \n",
      " 0.7630700778642936\n",
      "lags.py \n",
      " 0.43250688705234164\n",
      "lfw.py \n",
      " 0.5337650323774283\n",
      "linear.py \n",
      " 0.9852941176470589\n",
      "load-best-seeds-metrics.py \n",
      " 0.9877175025588536\n",
      "local.py \n",
      " 0.5570776255707763\n",
      "log.py \n",
      " 0.7414448669201521\n",
      "lossy.py \n",
      " 0.45977011494252873\n",
      "main.py \n",
      " 0.9907834101382489\n",
      "mean_segment_encoder.py \n",
      " 0.6036866359447004\n",
      "median_outliers.py \n",
      " 0.992619926199262\n",
      "merged.py \n",
      " 0.6519337016574586\n",
      "metrics.py \n",
      " 0.8239795918367347\n",
      "mlp.py \n",
      " 0.9009433962264151\n",
      "mnist.py \n",
      " 0.9479166666666666\n",
      "model.py \n",
      " 0.49256900212314225\n",
      "moving_average.py \n",
      " 0.9512195121951219\n",
      "mrmr_selection.py \n",
      " 0.9958071278825996\n",
      "multisim.py \n",
      " 0.9216417910447761\n",
      "mxnet.py \n",
      " 0.5510406342913776\n",
      "naive.py \n",
      " 0.9024390243902439\n",
      "nearest.py \n",
      " 0.689049262629432\n",
      "normal.py \n",
      " 0.444095038434661\n",
      "notebook_codespell.py \n",
      " 0.9902912621359223\n",
      "notebook_runner.py \n",
      " 1.0\n",
      "optimizer.py \n",
      " 0.6526458616010855\n",
      "pairs.py \n",
      " 0.587087087087087\n",
      "parametrization.py \n",
      " 0.5211148648648649\n",
      "pipeline.py \n",
      " 0.6123348017621145\n",
      "point_outliers.py \n",
      " 0.8589420654911839\n",
      "pooling.py \n",
      " 0.855072463768116\n",
      "power.py \n",
      " 0.9634703196347032\n",
      "predictability.py \n",
      " 0.6483050847457628\n",
      "prediction_interval_outliers.py \n",
      " 0.994475138121547\n",
      "preload.py \n",
      " 0.9197786998616874\n",
      "print-stages.py \n",
      " 0.9890710382513661\n",
      "prophet.py \n",
      " 0.6499567847882455\n",
      "proxynca.py \n",
      " 0.6680851063829787\n",
      "pytorch_forecasting.py \n",
      " 0.5158798283261803\n",
      "py_spy_to_df.py \n",
      " 0.99\n",
      "readme_updater.py \n",
      " 0.9872611464968153\n",
      "regularization_search.py \n",
      " 0.989778534923339\n",
      "release.py \n",
      " 0.9896640826873385\n",
      "relevance.py \n",
      " 0.9963735267452403\n",
      "relevance_table.py \n",
      " 0.9901153212520593\n",
      "remove_old_images.py \n",
      " 0.9859154929577465\n",
      "resample.py \n",
      " 0.5292307692307692\n",
      "resolvers.py \n",
      " 0.9272727272727272\n",
      "rotation.py \n",
      " 0.5\n",
      "run.py \n",
      " 0.9948186528497409\n",
      "sarimax.py \n",
      " 0.6286919831223629\n",
      "scale-images.py \n",
      " 0.7927107061503417\n",
      "scalers.py \n",
      " 0.9845261121856866\n",
      "scheduler.py \n",
      " 0.6507666098807496\n",
      "scorer.py \n",
      " 0.8239366963402572\n",
      "search.py \n",
      " 1.0\n",
      "seasonal_ma.py \n",
      " 0.804642166344294\n",
      "segment_encoder.py \n",
      " 0.9802955665024631\n",
      "serialize.py \n",
      " 0.9929577464788732\n",
      "settings.py \n",
      " 0.735444330949949\n",
      "setup.py \n",
      " 1.0\n",
      "shell.py \n",
      " 0.981651376146789\n",
      "significance_tests.py \n",
      " 0.9800853485064012\n",
      "sklearn.py \n",
      " 0.6191520467836258\n",
      "sop.py \n",
      " 0.5604026845637584\n",
      "special_days.py \n",
      " 0.5611814345991561\n",
      "split.py \n",
      " 0.7735849056603774\n",
      "stacking_ensemble.py \n",
      " 0.5703758290346352\n",
      "stanforddogs.py \n",
      " 0.7424242424242424\n",
      "stl.py \n",
      " 0.5683355886332881\n",
      "svhn.py \n",
      " 0.8240740740740741\n",
      "sweeps_example.py \n",
      " 0.9809523809523809\n",
      "tbats.py \n",
      " 0.7452316076294279\n",
      "td3_bc.py \n",
      " 0.8070692194403535\n",
      "templates.py \n",
      " 1.0\n",
      "test_assembling_pipelines.py \n",
      " 0.9977851605758582\n",
      "test_auto.py \n",
      " 0.9913419913419913\n",
      "test_autoregressive_pipeline.py \n",
      " 0.8902654867256637\n",
      "test_backtest.py \n",
      " 1.0\n",
      "test_base.py \n",
      " 0.9589257503949447\n",
      "test_base_change_points.py \n",
      " 0.9869848156182213\n",
      "test_base_feature_selection_transform.py \n",
      " 0.9933993399339934\n",
      "test_binseg_trend_transform.py \n",
      " 0.9811764705882353\n",
      "test_catboost.py \n",
      " 0.9870633893919794\n",
      "test_categorical_transform.py \n",
      " 0.8957365977205571\n",
      "test_change_points_segmentation_transform.py \n",
      " 0.910820451843044\n",
      "test_change_points_trend_transform.py \n",
      " 0.8405688622754491\n",
      "test_classification.py \n",
      " 0.9862068965517241\n",
      "test_classifier.py \n",
      " 0.8261464750171116\n",
      "test_clustering.py \n",
      " 0.9869960988296489\n",
      "test_commands.py \n",
      " 0.7874015748031495\n",
      "test_common.py \n",
      " 0.9738562091503268\n",
      "test_confidence_interval_outliers.py \n",
      " 0.9899244332493703\n",
      "test_config.py \n",
      " 0.48103792415169666\n",
      "test_config_sampler.py \n",
      " 0.978319783197832\n",
      "test_console_logger.py \n",
      " 0.993103448275862\n",
      "test_criterion.py \n",
      " 0.6871794871794872\n",
      "test_dataset.py \n",
      " 0.7903995229576625\n",
      "test_datasets_generation.py \n",
      " 0.9977653631284916\n",
      "test_dateflags_transform.py \n",
      " 0.9975475168608215\n",
      "test_deepar.py \n",
      " 0.9959390862944163\n",
      "test_density_outliers.py \n",
      " 0.9880478087649402\n",
      "test_detrend_transform.py \n",
      " 0.7059139784946237\n",
      "test_differencing_transform.py \n",
      " 0.8840232637700992\n",
      "test_direct_ensemble.py \n",
      " 0.9856459330143541\n",
      "test_distances.py \n",
      " 0.99137187230371\n",
      "test_distance_matrix.py \n",
      " 0.9919517102615694\n",
      "test_eda_utils.py \n",
      " 0.9932497589199615\n",
      "test_ensemble_mixin.py \n",
      " 0.9805825242718447\n",
      "test_feature_importance_transform.py \n",
      " 0.9951690821256038\n",
      "test_file_logger.py \n",
      " 0.8526483472720032\n",
      "test_filter_transform.py \n",
      " 0.866571018651363\n",
      "test_find_change_points.py \n",
      " 0.9886685552407932\n",
      "test_forecast.py \n",
      " 0.9812646370023419\n",
      "test_fourier_transform.py \n",
      " 0.8660785886126704\n",
      "test_functional_metrics.py \n",
      " 0.9769230769230769\n",
      "test_gale_shapley_transform.py \n",
      " 0.756702681072429\n",
      "test_hist_outliers.py \n",
      " 0.9986320109439124\n",
      "test_holiday_transform.py \n",
      " 0.8862413528055342\n",
      "test_holt_winters_model.py \n",
      " 0.9883268482490273\n",
      "test_impute_transform.py \n",
      " 0.8285805831464275\n",
      "test_interface.py \n",
      " 0.9919614147909968\n",
      "test_intervals_metrics.py \n",
      " 0.9843137254901961\n",
      "test_lag_transform.py \n",
      " 0.9881376037959668\n",
      "test_lambda_transform.py \n",
      " 0.9842342342342343\n",
      "test_linear_model.py \n",
      " 0.9874551971326165\n",
      "test_local.py \n",
      " 0.9813084112149533\n",
      "test_log_transform.py \n",
      " 0.9953917050691244\n",
      "test_mean_segment_encoder_transform.py \n",
      " 0.9889196675900277\n",
      "test_median_outliers.py \n",
      " 0.9940119760479041\n",
      "test_metrics.py \n",
      " 0.9928986442866365\n",
      "test_metrics_utils.py \n",
      " 0.981651376146789\n",
      "test_mixins.py \n",
      " 0.9892280071813285\n",
      "test_mlp.py \n",
      " 0.9946452476572959\n",
      "test_model.py \n",
      " 0.652037617554859\n",
      "test_mrmr.py \n",
      " 0.9944392956441149\n",
      "test_multisim.py \n",
      " 1.0\n",
      "test_nearest.py \n",
      " 0.6625\n",
      "test_normal.py \n",
      " 0.5867768595041323\n",
      "test_optimizer.py \n",
      " 0.9960238568588469\n",
      "test_outliers_transform.py \n",
      " 0.9934282584884995\n",
      "test_parametrization.py \n",
      " 0.993127147766323\n",
      "test_pipeline.py \n",
      " 0.8821964658939768\n",
      "test_plotters.py \n",
      " 0.8754160722776985\n",
      "test_pool.py \n",
      " 0.9847328244274809\n",
      "test_power_transform.py \n",
      " 0.9882926829268293\n",
      "test_predict.py \n",
      " 0.6334256694367497\n",
      "test_prophet.py \n",
      " 0.9861111111111112\n",
      "test_proxynca.py \n",
      " 0.9787234042553191\n",
      "test_pytorch_forecasting_transform.py \n",
      " 0.9854014598540146\n",
      "test_quality.py \n",
      " 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_regularization_search.py \n",
      " 0.9911894273127754\n",
      "test_relevance.py \n",
      " 0.9841269841269842\n",
      "test_relevance_table.py \n",
      " 0.7716857610474632\n",
      "test_reproducibility.py \n",
      " 0.7447619047619047\n",
      "test_resample_transform.py \n",
      " 0.9946666666666667\n",
      "test_rnn.py \n",
      " 1.0\n",
      "test_sampler.py \n",
      " 0.6691358024691358\n",
      "test_sarimax_model.py \n",
      " 0.8574585635359115\n",
      "test_scalers_transform.py \n",
      " 0.9809782608695652\n",
      "test_segment_encoder_transform.py \n",
      " 1.0\n",
      "test_simple_models.py \n",
      " 0.7519984012789769\n",
      "test_sklearn.py \n",
      " 0.9864864864864865\n",
      "test_sklearn_transform_interface.py \n",
      " 0.9919614147909968\n",
      "test_special_days_transform.py \n",
      " 0.9841269841269842\n",
      "test_stacking_ensemble.py \n",
      " 0.926829268292683\n",
      "test_stages.py \n",
      " 0.5322812051649928\n",
      "test_statistics_transform.py \n",
      " 0.9333333333333333\n",
      "test_stl_transform.py \n",
      " 0.988834612700628\n",
      "test_tbats.py \n",
      " 0.9971387696709585\n",
      "test_tft.py \n",
      " 0.9920477137176938\n",
      "test_to_dict.py \n",
      " 0.988833746898263\n",
      "test_transform.py \n",
      " 0.5498371335504886\n",
      "test_transform_quantiles.py \n",
      " 0.9863481228668942\n",
      "test_trend_transform.py \n",
      " 0.8150851581508516\n",
      "test_tsfresh.py \n",
      " 0.9619047619047619\n",
      "test_utils.py \n",
      " 0.983440662373505\n",
      "test_verification.py \n",
      " 0.9948051948051948\n",
      "test_vmf.py \n",
      " 0.6837121212121212\n",
      "test_wandb_logger.py \n",
      " 1.0\n",
      "test_weasel.py \n",
      " 0.9855769230769231\n",
      "test_wrapper.py \n",
      " 0.9507389162561576\n",
      "tft.py \n",
      " 0.6690140845070423\n",
      "time_flags.py \n",
      " 0.9075067024128687\n",
      "torch.py \n",
      " 0.9661016949152542\n",
      "trace.py \n",
      " 0.9907834101382489\n",
      "trainer.py \n",
      " 0.47931034482758617\n",
      "tsdataset.py \n",
      " 0.5087719298245614\n",
      "tsfresh.py \n",
      " 0.9624413145539906\n",
      "utils.py \n",
      " 0.9941176470588236\n",
      "variance_scheduler.py \n",
      " 0.5541125541125541\n",
      "verification.py \n",
      " 0.7693333333333333\n",
      "vmf.py \n",
      " 0.5312050618349151\n",
      "voting_ensemble.py \n",
      " 0.4715852442671984\n",
      "wandb_logger.py \n",
      " 0.49815043156596794\n",
      "weasel.py \n",
      " 0.7933032839665164\n",
      "wrapper.py \n",
      " 0.6577946768060836\n",
      "__init__.py \n",
      " 1\n",
      "__main__.py \n",
      " 1.0\n"
     ]
    }
   ],
   "source": [
    "scores = 0\n",
    "cnt = 0\n",
    "\n",
    "for name in os.listdir('files'):\n",
    "    cnt += 1\n",
    "    code1 = code_to_list(read_code(name, 'files'))\n",
    "    code2 = code_to_list(read_code(name, 'plagiat1'))\n",
    "    score = wagner_fisher(code1, code2)\n",
    "    scores += score\n",
    "    print(name, '\\n', score)\n",
    "\n",
    "print(scores/cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0b50c6",
   "metadata": {},
   "source": [
    "Можем заметить, что в большинстве случаев наш простой алгоритм даёт на плагиате score более 0.9. Но иногда значение опускается ниже 0.5. Достаточно ли такого такого алгоритма чтобы отличить плагиат от не-плагиата в большинстве случаев? Давайте попробуем сделать произвольную выборку из приблизительно 200 кодов, которые не являются плагиатами друг друга и посмотрим на score, который получают эти программы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6b9021b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline.py generate-reality.py \n",
      " 0.4571984435797666\n",
      "test_auto.py direct_ensemble.py \n",
      " 0.4570596797671034\n",
      "relevance_table.py tbats.py \n",
      " 0.4508196721311475\n",
      "edac.py tsdataset.py \n",
      " 0.4515356131561751\n",
      "\n",
      " __________________________________________________ \n",
      "result: 0.27005094830980353\n"
     ]
    }
   ],
   "source": [
    "scores = 0\n",
    "cnt = 0\n",
    "\n",
    "names_list = os.listdir('files')\n",
    "codes1, codes2 = choices(names_list, k=200), choices(names_list, k=200)\n",
    "\n",
    "for name1, name2 in zip(codes1, codes2):\n",
    "    if name1 != name2:\n",
    "        cnt += 1\n",
    "        code1 = code_to_list(read_code(name1, 'files'))\n",
    "        code2 = code_to_list(read_code(name2, 'plagiat1'))\n",
    "        score = wagner_fisher(code1, code2)\n",
    "        if score > 0.45:\n",
    "            print(name1, name2, '\\n', score)\n",
    "        scores += score\n",
    "        \n",
    "\n",
    "print('\\n', 50*'_', '\\nresult:', scores/cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5200d18",
   "metadata": {},
   "source": [
    "Во время моего запуска кода на 197 случайных сравнениях, средний score был около 0.27 и почти ни в каких сравнениях score не был выше 0.5. Выполним проверку модели на полностью случайных выборках:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e631cd53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 \t\t 0.9965367965367965\n",
      "1 2 \t\t 0.9904306220095693\n",
      "2 3 \t\t 0.7443840579710145\n",
      "3 4 \t\t 0.9595959595959596\n",
      "4 5 \t\t 0.5366161616161615\n",
      "5 6 \t\t 0.9914376742333731\n",
      "6 7 \t\t 0.9955995599559956\n",
      "7 8 \t\t 0.9954998392799743\n",
      "8 9 \t\t 0.9918116683725691\n",
      "9 10 \t\t 0.5275707898658719\n",
      "10 11 \t\t 0.9440459110473458\n",
      "11 12 \t\t 1.0\n",
      "12 13 \t\t 0.9951865222623345\n",
      "13 14 \t\t 0.9906103286384976\n",
      "14 15 \t\t 0.9896840747904577\n",
      "15 16 \t\t 0.621933621933622\n",
      "16 17 \t\t 0.9595959595959596\n",
      "17 18 \t\t 1.0\n",
      "18 19 \t\t 0.6334459459459459\n",
      "19 20 \t\t 0.825287356321839\n",
      "20 21 \t\t 0.6784037558685446\n",
      "21 22 \t\t 0.6919475655430711\n",
      "22 23 \t\t 0.6703947997323392\n",
      "23 24 \t\t 0.7890295358649789\n",
      "24 25 \t\t 0.5679627783316716\n",
      "25 26 \t\t 0.8508098891730606\n",
      "26 27 \t\t 1.0\n",
      "27 28 \t\t 0.9955377063810799\n",
      "28 29 \t\t 0.9941262848751835\n",
      "29 30 \t\t 0.8828451882845189\n",
      "30 31 \t\t 0.6322333811573411\n",
      "31 32 \t\t 0.6427604871447903\n",
      "32 33 \t\t 0.9921104536489151\n",
      "33 34 \t\t 0.985546522131888\n",
      "34 35 \t\t 0.9990880072959416\n",
      "35 36 \t\t 0.7230929989550678\n",
      "36 37 \t\t 0.8987108655616943\n",
      "37 38 \t\t 0.881965051104517\n",
      "38 39 \t\t 0.8919660678642715\n",
      "39 40 \t\t 0.66402378592666\n",
      "40 41 \t\t 0.9972047519217331\n",
      "41 42 \t\t 0.7696893630373391\n",
      "42 43 \t\t 0.6143589743589744\n",
      "43 44 \t\t 0.9906103286384976\n",
      "44 45 \t\t 0.9894179894179894\n",
      "45 46 \t\t 0.9312106918238994\n",
      "46 47 \t\t 0.7047047047047047\n",
      "47 48 \t\t 0.9472401433691756\n",
      "48 49 \t\t 0.7546933667083855\n",
      "49 50 \t\t 0.5980271270036992\n",
      "50 51 \t\t 0.9920318725099602\n",
      "51 52 \t\t 0.9908045977011495\n",
      "52 53 \t\t 0.66402378592666\n",
      "53 54 \t\t 0.9967793880837359\n",
      "54 55 \t\t 0.9907407407407407\n",
      "55 56 \t\t 0.650814332247557\n",
      "56 57 \t\t 0.7476391400442033\n",
      "57 58 \t\t 0.9756468797564688\n",
      "58 59 \t\t 0.7246376811594203\n",
      "59 60 \t\t 0.997411003236246\n",
      "60 61 \t\t 0.994634473507713\n",
      "61 62 \t\t 0.6427604871447903\n",
      "62 63 \t\t 0.9913307325530992\n",
      "63 64 \t\t 0.6696143453696881\n",
      "64 65 \t\t 0.9900497512437811\n",
      "65 66 \t\t 0.7873015873015873\n",
      "66 67 \t\t 0.9931856899488927\n",
      "67 68 \t\t 0.9955377063810799\n",
      "68 69 \t\t 0.825287356321839\n",
      "69 70 \t\t 0.8987108655616943\n",
      "70 71 \t\t 1.0\n",
      "71 72 \t\t 0.8940818584070797\n",
      "72 73 \t\t 0.650814332247557\n",
      "73 74 \t\t 0.6427604871447903\n",
      "74 75 \t\t 0.9877675840978594\n",
      "75 76 \t\t 0.9369973190348525\n",
      "76 77 \t\t 0.650814332247557\n",
      "77 78 \t\t 0.9896840747904577\n",
      "78 79 \t\t 0.9515151515151515\n",
      "79 80 \t\t 0.9954022988505747\n",
      "80 81 \t\t 0.8333333333333334\n",
      "81 82 \t\t 0.9913232104121475\n",
      "82 83 \t\t 0.9875389408099688\n",
      "83 84 \t\t 0.7293144208037825\n",
      "84 85 \t\t 0.9757575757575757\n",
      "85 86 \t\t 0.6427604871447903\n",
      "86 87 \t\t 0.9911991199119912\n",
      "87 88 \t\t 0.9955377063810799\n",
      "88 89 \t\t 0.9986504723346828\n",
      "89 90 \t\t 0.8377952755905511\n",
      "90 91 \t\t 0.7752873563218391\n",
      "91 92 \t\t 0.7443840579710145\n",
      "92 93 \t\t 0.8828451882845189\n",
      "93 94 \t\t 0.9933333333333333\n",
      "94 95 \t\t 1.0\n",
      "95 96 \t\t 0.8528622540250448\n",
      "96 97 \t\t 0.9104517508687516\n",
      "97 98 \t\t 0.995418098510882\n",
      "98 99 \t\t 0.9901960784313726\n",
      "99 100 \t\t 0.550896808758444\n",
      "100 101 \t\t 0.9825708061002179\n",
      "101 102 \t\t 0.9901960784313726\n",
      "102 103 \t\t 0.9931856899488927\n",
      "103 104 \t\t 0.9907407407407407\n",
      "104 105 \t\t 0.9923119165293794\n",
      "105 106 \t\t 1.0\n",
      "106 107 \t\t 0.9867235656709341\n",
      "107 108 \t\t 0.9312106918238994\n",
      "108 109 \t\t 0.8991105801141643\n",
      "109 110 \t\t 1.0\n",
      "110 111 \t\t 0.881965051104517\n",
      "111 112 \t\t 0.8816568047337279\n",
      "112 113 \t\t 1.0\n",
      "113 114 \t\t 0.8364849833147943\n",
      "114 115 \t\t 0.9918116683725691\n",
      "115 116 \t\t 0.9914376742333731\n",
      "116 117 \t\t 0.8784013605442177\n",
      "117 118 \t\t 0.8528622540250448\n",
      "118 119 \t\t 0.6091256948956754\n",
      "119 120 \t\t 0.7443840579710145\n",
      "120 121 \t\t 0.5980271270036992\n",
      "121 122 \t\t 0.9902723735408561\n",
      "122 123 \t\t 0.7695716395864106\n",
      "123 124 \t\t 0.8276299112801013\n",
      "124 125 \t\t 0.9990880072959416\n",
      "125 126 \t\t 0.9918116683725691\n",
      "126 127 \t\t 0.9922178988326849\n",
      "127 128 \t\t 0.995079950799508\n",
      "128 129 \t\t 1.0\n",
      "129 130 \t\t 0.8987108655616943\n",
      "130 131 \t\t 0.5275707898658719\n",
      "131 132 \t\t 0.6902887139107612\n",
      "132 133 \t\t 1.0\n",
      "133 134 \t\t 0.9935275080906149\n",
      "134 135 \t\t 0.8919660678642715\n",
      "135 136 \t\t 0.9774011299435028\n",
      "136 137 \t\t 0.6784037558685446\n",
      "137 138 \t\t 0.6696143453696881\n",
      "138 139 \t\t 0.9953051643192489\n",
      "139 140 \t\t 0.9169802714106512\n",
      "140 141 \t\t 0.9973492379058979\n",
      "141 142 \t\t 0.54178145087236\n",
      "142 143 \t\t 0.6267855430927045\n",
      "143 144 \t\t 0.967479674796748\n",
      "144 145 \t\t 0.6054421768707483\n",
      "145 146 \t\t 0.9913755929279862\n",
      "146 147 \t\t 0.7246376811594203\n",
      "147 148 \t\t 0.9472401433691756\n",
      "148 149 \t\t 0.5821759259259259\n",
      "149 150 \t\t 0.9877675840978594\n",
      "150 151 \t\t 0.9369973190348525\n",
      "151 152 \t\t 0.6919475655430711\n",
      "152 153 \t\t 0.6322333811573411\n",
      "153 154 \t\t 0.766540404040404\n",
      "154 155 \t\t 0.8364849833147943\n",
      "155 156 \t\t 0.9472401433691756\n",
      "156 157 \t\t 0.9465408805031447\n",
      "157 158 \t\t 0.9889604415823368\n",
      "158 159 \t\t 0.9858156028368794\n",
      "159 160 \t\t 0.9941262848751835\n",
      "160 161 \t\t 0.793189964157706\n",
      "161 162 \t\t 0.9746031746031746\n",
      "162 163 \t\t 0.9595959595959596\n",
      "163 164 \t\t 0.8028600612870276\n",
      "164 165 \t\t 0.7441860465116279\n",
      "165 166 \t\t 0.9925093632958801\n",
      "166 167 \t\t 0.7476391400442033\n",
      "167 168 \t\t 0.7359454855195912\n",
      "168 169 \t\t 0.9975823511634935\n",
      "169 170 \t\t 0.9967793880837359\n",
      "170 171 \t\t 0.9877675840978594\n",
      "171 172 \t\t 0.990990990990991\n",
      "172 173 \t\t 0.9811142587346553\n",
      "173 174 \t\t 0.9908987485779295\n",
      "174 175 \t\t 0.6799516908212561\n",
      "175 176 \t\t 1.0\n",
      "176 177 \t\t 1.0\n",
      "177 178 \t\t 0.9957671957671957\n",
      "178 179 \t\t 0.862194843714351\n",
      "179 180 \t\t 0.7047047047047047\n",
      "180 181 \t\t 0.8828451882845189\n",
      "181 182 \t\t 0.8097643097643098\n",
      "182 183 \t\t 0.8446170921198668\n",
      "183 184 \t\t 0.8796296296296297\n",
      "184 185 \t\t 0.9960079840319361\n",
      "185 186 \t\t 0.9986504723346828\n",
      "186 187 \t\t 0.9213372664700098\n",
      "187 188 \t\t 0.9825708061002179\n",
      "188 189 \t\t 0.9894179894179894\n",
      "189 190 \t\t 0.9931093884582257\n",
      "190 191 \t\t 0.7752873563218391\n",
      "191 192 \t\t 0.8987108655616943\n",
      "192 193 \t\t 0.9931093884582257\n",
      "193 194 \t\t 0.9979612640163099\n",
      "194 195 \t\t 0.9920917358639778\n",
      "195 196 \t\t 0.9652777777777778\n",
      "196 197 \t\t 0.994572591587517\n",
      "197 198 \t\t 0.6322333811573411\n",
      "198 199 \t\t 0.8979591836734694\n",
      "199 200 \t\t 0.9956188389923329\n",
      "200 201 \t\t 0.4151329243353783\n",
      "201 202 \t\t 0.3824074074074074\n",
      "202 203 \t\t 0.3910229351343746\n",
      "203 204 \t\t 0.38081790607677024\n",
      "204 204 \t\t 0.5100719424460431\n",
      "205 205 \t\t 0.2417061611374408\n",
      "206 205 \t\t 0.47759497057249867\n",
      "207 205 \t\t 0.4819338422391858\n",
      "208 205 \t\t 0.4705205637043428\n",
      "209 206 \t\t 0.3604826546003017\n",
      "210 206 \t\t 0.5023640661938534\n",
      "211 206 \t\t 0.5444444444444445\n",
      "212 207 \t\t 0.4253187613843351\n",
      "213 207 \t\t 0.5112321957747825\n",
      "214 207 \t\t 0.5499351491569391\n",
      "215 207 \t\t 0.4906093189964158\n",
      "216 207 \t\t 0.5182895414734673\n",
      "217 207 \t\t 0.5283392786365437\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-118-8f13f8bfeea6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mgen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mone_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwagner_fisher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mdivision\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m200\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mdivision\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m200\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m                 \u001b[0mscores\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-76-a49588772155>\u001b[0m in \u001b[0;36mwagner_fisher\u001b[1;34m(code1, code2, rep_cost, del_cost, ins_cost)\u001b[0m\n\u001b[0;32m      7\u001b[0m                 \u001b[0mnew_line\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdel_cost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m                 new_line[j] = min(prev_line[j] + del_cost, \n\u001b[0m\u001b[0;32m     10\u001b[0m                                   \u001b[0mnew_line\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mins_cost\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                                   prev_line[j - 1] + rep_cost * (code1[i] != code2[j]))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def one_batch(alphabet=os.listdir('files'), size=200):\n",
    "    for file in choices(alphabet, k=size):\n",
    "        yield code_to_list(read_code(file, 'files')), code_to_list(read_code(file, 'plagiat1'))\n",
    "    for i in range(200):\n",
    "        file1, file2 = choice(alphabet), choice(alphabet)\n",
    "        while file1 == file2:\n",
    "            file1, file2 = choice(alphabet), choice(alphabet)\n",
    "        yield code_to_list(read_code(file1, 'files')), code_to_list(read_code(file2, 'plagiat1'))\n",
    "\n",
    "        \n",
    "price, division = 1, 0.45\n",
    "scores = 0\n",
    "gen = one_batch()\n",
    "for i in range(400):\n",
    "    result = wagner_fisher(*next(gen), price)\n",
    "    if result > division and i // 200 == 0 or result <= division and i // 200 == 1:\n",
    "        scores += 1\n",
    "    print(i, scores, '\\t\\t', result)\n",
    "with open('model.txt', 'w') as model:\n",
    "    model.write(str(price) + ' ' + str(division) + ':\\t;t' + str(scores / 400) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053d0999",
   "metadata": {},
   "source": [
    "Параметры price = 1, division = 0.45 позволяют добиться 98% точности, что можно считать достаточным. Для того, чтобы нормализовать результат (чтобы границей было 0.5) мы пожертвуем точностью на краях распределения и повысим оценку каждой пары до min(1, 0.05 + score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9aaefbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "30b243f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_ast.Import,\n",
       " _ast.alias,\n",
       " _ast.ImportFrom,\n",
       " _ast.ClassDef,\n",
       " _ast.Name,\n",
       " _ast.Load,\n",
       " _ast.Expr,\n",
       " _ast.Constant,\n",
       " _ast.FunctionDef,\n",
       " _ast.arguments,\n",
       " _ast.arg,\n",
       " _ast.Subscript,\n",
       " _ast.Index,\n",
       " _ast.Assign,\n",
       " _ast.Attribute,\n",
       " _ast.Store,\n",
       " _ast.If,\n",
       " _ast.Call,\n",
       " _ast.Return,\n",
       " _ast.ExtSlice,\n",
       " _ast.Slice,\n",
       " _ast.BinOp,\n",
       " _ast.Add,\n",
       " _ast.keyword,\n",
       " _ast.List,\n",
       " _ast.Tuple,\n",
       " _ast.Sub,\n",
       " _ast.Compare,\n",
       " _ast.Eq,\n",
       " _ast.For,\n",
       " _ast.Mult,\n",
       " _ast.Div,\n",
       " _ast.Raise,\n",
       " _ast.UnaryOp,\n",
       " _ast.USub,\n",
       " _ast.Dict,\n",
       " _ast.comprehension,\n",
       " _ast.Assert]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "55bf8c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"alphabet\", \"wb\") as fp:   \n",
    "    pickle.dump(alphabet, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ae68de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
